{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d339647-b5be-4fac-badb-af02c0811fce",
   "metadata": {
    "id": "A547k4aK4Wpe",
    "tags": []
   },
   "source": [
    "# **downloadMeteoData.ipynb**\n",
    "\n",
    "Author: Zhixian Yang\n",
    "\n",
    "Email: [yangzhx28@mail2.sysu.edu.cn](mailto:yangzhx28@mail2.sysu.edu.cn) or [yimu01439@gmail.com](mailto:yimu01439@gmail.com)\n",
    "\n",
    "GitHub: [https://github.com/koar-create](https://github.com/koar-create)\n",
    "\n",
    "Date created: August 2th, 2023\n",
    "\n",
    "Last modified: August 10th, 2023\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## **Description**\n",
    "None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e61d8c-873b-496f-830a-94e95e071d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No updates required for final_record_date.csv.\n",
      "The last update was made 2.76 hours ago.\n",
      "No updates required for final_record_date.csv.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob\n",
    "import pytz\n",
    "import requests\n",
    "import platform\n",
    "import numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def import_station_info(dirname=None):\n",
    "    addr_filename = 'stations.xlsx' # another one is 'China_SURF_Station.xlsx'\n",
    "    if not os.path.exists(os.path.join(dirname, addr_filename)):\n",
    "        print(f\"{addr_filename} does not exist, run Reorganizing_addr_sheet.py first.\")\n",
    "        sys.exit()\n",
    "    df_addr = pd.read_excel(os.path.join(dirname, addr_filename), sheet_name='开放站点')\n",
    "    sites     = df_addr['区站号'].values\n",
    "    provinces = df_addr['省份'  ].values\n",
    "    stations  = df_addr['站名'  ].values\n",
    "    return sites, provinces, stations\n",
    "\n",
    "def synchronize(sites=None, dirname=None):\n",
    "    data_dirname = os.path.join(dirname, 'data')\n",
    "    china_timezone = pytz.timezone('Asia/Shanghai')\n",
    "    \n",
    "    # create 'final_record_date.csv'\n",
    "    if not os.path.exists(os.path.join(dirname, 'final_record_date.csv')):\n",
    "        datetime_final_records = np.array([])\n",
    "        for site in sites:\n",
    "            \n",
    "            # obtain corresponding paths\n",
    "            existing_abspath = glob.glob(os.path.join(data_dirname, f\"*{site}.csv\"))\n",
    "            if existing_abspath:\n",
    "                existing_filename = [fpath.split(os.sep)[-1] for fpath in existing_abspath]\n",
    "                datetime_final_record = china_timezone.localize(max([datetime.strptime(fname.split('.')[0].split('-')[-1], '%y%m%d%H') for fname in existing_filename]))\n",
    "            else:\n",
    "                datetime_final_record = datetime(2023, 8, 1, 0, tzinfo=china_timezone)\n",
    "            datetime_final_records = np.append(datetime_final_records, datetime_final_record)\n",
    "        df_update = pd.DataFrame({'number': sites, 'final record date': datetime_final_records})\n",
    "        df_update.to_csv(os.path.join(dirname, 'final_record_date.csv'), encoding='utf-8', index=False)\n",
    "        print('Successfully create final_record_date.csv!')\n",
    "        \n",
    "    # read and update 'final_record_date.csv'\n",
    "    else:\n",
    "        df_update = pd.read_csv(os.path.join(dirname, 'final_record_date.csv'))\n",
    "        df_update.set_index('number', inplace=True)\n",
    "        \n",
    "        change = False\n",
    "        for site in sites:\n",
    "                \n",
    "            # obtain corresponding paths\n",
    "            existing_abspath = glob.glob(os.path.join(data_dirname, f\"*{site}.csv\"))\n",
    "            if existing_abspath:\n",
    "                existing_filename = [fpath.split(os.sep)[-1] for fpath in existing_abspath]\n",
    "                datetime_final_record = china_timezone.localize(max([datetime.strptime(fname.split('.')[0].split('-')[-1], '%y%m%d%H') for fname in existing_filename])) # 23080113-23080212.59488.csv\n",
    "                if type(df_update.loc[site, 'final record date']) == str:\n",
    "                    df_update.loc[site, 'final record date'] = china_timezone.localize(datetime.strptime(df_update.loc[site, 'final record date'][:-6], '%Y-%m-%d %H:%M:%S'))\n",
    "                if datetime_final_record > df_update.loc[site, 'final record date']:\n",
    "                    df_update.loc[site, 'final record date'] = datetime_final_record\n",
    "                    change = True\n",
    "                    \n",
    "        if change == True:\n",
    "            df_update.reset_index(inplace=True)\n",
    "            df_update.to_csv(os.path.join(dirname, 'final_record_date.csv'), encoding='utf-8', index=False)\n",
    "            print('Successfully update final_record_date.csv to the latest state!')\n",
    "        else:\n",
    "            print('No updates required for final_record_date.csv.')\n",
    "    return df_update\n",
    "\n",
    "def daily_auto_download(df_update=None, interval=12, mode='stable', dirname=None):\n",
    "    data_dirname = os.path.join(dirname, 'data')\n",
    "    sites, provinces, stations = import_station_info(dirname=dirname)\n",
    "    len_p, len_s = max(len(i) for i in provinces), max(len(ii) for ii in stations)\n",
    "    total_hours = []\n",
    "    china_timezone = pytz.timezone('Asia/Shanghai')\n",
    "    if 'number' in df_update.columns:\n",
    "        df_update.set_index('number', inplace=True)\n",
    "    \n",
    "    for site, province, station in zip(sites, provinces, stations):\n",
    "        url = f\"https://q-weather.info/weather/{site}/today/\"\n",
    "        \n",
    "        # skip updated data\n",
    "        datetime_now = datetime.now(china_timezone)\n",
    "        if type(df_update.loc[site, 'final record date']) == str:\n",
    "            df_update.loc[site, 'final record date'] = china_timezone.localize(datetime.strptime(df_update.loc[site, 'final record date'][:-6], '%Y-%m-%d %H:%M:%S'))\n",
    "        total_hours.append((datetime_now - df_update.loc[site, 'final record date']).total_seconds())\n",
    "        if (datetime_now - df_update.loc[site, 'final record date']).total_seconds() <= (interval / 24 * 86400):\n",
    "            continue\n",
    "            \n",
    "        success = False\n",
    "        while not success:\n",
    "            try:\n",
    "                headers = headers = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7', 'Connection': 'keep-alive', 'Host': 'q-weather.info', 'Referer': 'https://www.google.com/', 'Sec-Ch-Ua-Platform': \"Windows\", 'Sec-Fetch-Dest': 'document', 'Sec-Fetch-Mode': 'navigate', 'Sec-Fetch-Site': 'cross-site', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}\n",
    "                response = requests.get(url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"!!!!Error while fetching the webpage: {e}\", \"\\n\", f\"~~~~[{site}]\")\n",
    "                time.sleep(10)\n",
    "            try:\n",
    "                df = pd.read_html(response.content)[0]\n",
    "                \n",
    "                # assign new column, reorder columns, rename visibility, remove '时次'\n",
    "                df['number'] = site\n",
    "                df = df.loc[:, ['number'] + list(df.columns[:-1])]\n",
    "                if '能见度' in df.columns:\n",
    "                    df.rename(columns={'能见度': '10分钟平均能见度'}, inplace=True)\n",
    "                if ('时次' in df.columns):\n",
    "                    for idx in df.index:\n",
    "                        date = datetime.strptime(df.loc[idx, '时次'][:-6], '%Y-%m-%d %H:%M')\n",
    "                        df.loc[idx, 'year' ] = date.year\n",
    "                        df.loc[idx, 'month'] = date.month\n",
    "                        df.loc[idx, 'day'  ] = date.day\n",
    "                        df.loc[idx, 'hour' ] = date.hour\n",
    "                    for label in ['number', 'year', 'month', 'day', 'hour']:\n",
    "                        df[label] = df[label].astype(np.int64)\n",
    "                    df.drop(columns=['时次'], inplace=True)\n",
    "                    df.sort_values(by=['number', 'year', 'month', 'day', 'hour'], ascending=[True, True, True, True, True], inplace=True)\n",
    "                    df.reset_index(inplace=True)\n",
    "                    df.drop(columns=['index'], inplace=True)\n",
    "                \n",
    "                # save sheet as csv file\n",
    "                l = df.shape[0]\n",
    "                start_date = datetime(df.loc[  0, 'year'], df.loc[  0, 'month'], df.loc[  0, 'day'], df.loc[  0, 'hour'], tzinfo=china_timezone).strftime('%y%m%d%H')\n",
    "                end_date   = datetime(df.loc[l-1, 'year'], df.loc[l-1, 'month'], df.loc[l-1, 'day'], df.loc[l-1, 'hour'], tzinfo=china_timezone).strftime('%y%m%d%H')\n",
    "                filename = f\"{start_date}-{end_date}.{site}.csv\"\n",
    "                df.to_csv(os.path.join(data_dirname, filename), index=False, encoding='utf-8')\n",
    "                print(f\"--{province}{chr(12288) * (len_p - len(province))}, {station}{chr(12288) * (len_s - len(station))}. Saved as {filename}\")\n",
    "                \n",
    "                # sleep randomly\n",
    "                sleep_time = max(np.abs(0.1 + 0.1 * np.random.randn(1)[0]), 0)\n",
    "                time.sleep(sleep_time)\n",
    "                success = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"!!!!An error occurred: {e} \\n [{site}]\")\n",
    "                sys.exit()\n",
    "    print(f\"The last update was made {(max(total_hours)/3600):.2f} hours ago.\")\n",
    "    \n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    dirname = os.getcwd()\n",
    "elif platform.system() == 'Windows':\n",
    "    dirname = os.path.join(\"D:\\\\Documents\", \"A-threads\", \"less important ones\", \"thread2308-4_try_to_purchase_chinese_station_api\")\n",
    "\n",
    "sites, provinces, stations = import_station_info(dirname=dirname)\n",
    "df_update = synchronize(sites=sites, dirname=dirname)\n",
    "daily_auto_download(df_update=df_update, interval=8, mode='stable', dirname=dirname)\n",
    "_ = synchronize(sites=sites, dirname=dirname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
